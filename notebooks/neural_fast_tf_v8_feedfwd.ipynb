{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#most of the code for feed forward generation is the same as the training code. some unnecessary code is removed.\n",
    "import os\n",
    "import sys\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import imageio\n",
    "import h5py\n",
    "import tables\n",
    "import vgg \n",
    "from decimal import Decimal\n",
    "import pickle\n",
    "import gzip\n",
    "import time\n",
    "import functools\n",
    "from functools import reduce\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_path = \"../models/imagenet-vgg-verydeep-19.mat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_initializer(weight_input, output_channel_size, filter_size, deconv = False):\n",
    "    \n",
    "    _, rows, columns, input_channel_size = [i.value for i in weight_input.get_shape()]\n",
    "    \n",
    "    if deconv:\n",
    "        weight_shape = [filter_size,filter_size,output_channel_size,input_channel_size]\n",
    "    else:\n",
    "        weight_shape = [filter_size,filter_size,input_channel_size,output_channel_size]\n",
    "\n",
    "    weight_output = tf.Variable(tf.truncated_normal(weight_shape, stddev=0.1, seed=1), dtype=tf.float32)\n",
    "    \n",
    "    return weight_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def instance_norm(net, train=True):\n",
    "    batch, rows, cols, channels = [i.value for i in net.get_shape()]\n",
    "    var_shape = [channels]\n",
    "    mu, sigma_sq = tf.nn.moments(net, [1,2], keep_dims=True)\n",
    "    shift = tf.Variable(tf.zeros(var_shape))\n",
    "    scale = tf.Variable(tf.ones(var_shape))\n",
    "    epsilon = 1e-3\n",
    "    normalized = (net-mu)/(sigma_sq + epsilon)**(.5)\n",
    "    return scale * normalized + shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(block_input, num_filters, filter_size, stride_length, use_relu = True):\n",
    "    \n",
    "    init_weights = weight_initializer(block_input, num_filters, filter_size)\n",
    "    strides = [1,stride_length,stride_length,1]\n",
    "    block_output = tf.nn.conv2d(block_input,init_weights,strides,padding='SAME')\n",
    "    \n",
    "    block_output = instance_norm(block_output)\n",
    "    \n",
    "    if use_relu:\n",
    "        block_output = tf.nn.relu(block_output)\n",
    "    \n",
    "    return block_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_transpose_block(block_input, num_filters, filter_size, stride_length):\n",
    "    \n",
    "    init_weights = weight_initializer(block_input, num_filters, filter_size, deconv = True)\n",
    "    \n",
    "    batch_size, rows, cols, in_channels = [i.value for i in (block_input).get_shape()]\n",
    "    new_rows, new_cols = int(rows * stride_length), int(cols * stride_length)\n",
    "    batch_size = tf.shape(block_input)[0]\n",
    "    new_shape = [batch_size, new_rows, new_cols, num_filters]\n",
    "    tf_shape = tf.stack(new_shape)\n",
    "    strides = [1,stride_length,stride_length,1]\n",
    "    \n",
    "    block_output = tf.nn.conv2d_transpose(block_input, init_weights, tf_shape, strides, padding='SAME')\n",
    "    \n",
    "    block_output = instance_norm(block_output)\n",
    "    \n",
    "    return tf.nn.relu(block_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(block_input, filter_size = 3, num_filters = 128):\n",
    "    temp = conv_block(block_input, num_filters, filter_size, 1)\n",
    "    return block_input + conv_block(temp, num_filters, filter_size, 1, use_relu = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the input model\n",
    "def fast_model(input_image):\n",
    "    conv_1 = conv_block(input_image, 32, 9, 1)\n",
    "    conv_2 = conv_block(conv_1, 64, 3, 2)\n",
    "    conv_3 = conv_block(conv_2, 128, 3, 2)\n",
    "    \n",
    "    res_1 = residual_block(conv_3, 3, 128) \n",
    "    res_2 = residual_block(res_1, 3, 128)\n",
    "    res_3 = residual_block(res_2, 3, 128)\n",
    "    res_4 = residual_block(res_3, 3, 128)\n",
    "    res_5 = residual_block(res_4, 3, 128)\n",
    "    \n",
    "    conv_t_1 = conv_transpose_block(res_5, 64, 3, 2)\n",
    "    conv_t_2 = conv_transpose_block(conv_t_1, 32, 3, 2)\n",
    "    conv_t_3 = conv_block(conv_t_2, 3, 9, 1, use_relu = False)\n",
    "    final_output = tf.nn.tanh(conv_t_3)*150 + 255.0/2\n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_variation(layer):\n",
    "\n",
    "    shape = tf.shape(layer)\n",
    "    height = shape[1]\n",
    "    width = shape[2]\n",
    "    y = tf.slice(layer, [0,0,0,0], tf.stack([-1,height-1,-1,-1])) - tf.slice(layer, [0,1,0,0], [-1,-1,-1,-1])\n",
    "    x = tf.slice(layer, [0,0,0,0], tf.stack([-1,-1,width-1,-1])) - tf.slice(layer, [0,0,1,0], [-1,-1,-1,-1])\n",
    "    tloss = tf.nn.l2_loss(x) / tf.to_float(tf.size(x)) + tf.nn.l2_loss(y) / tf.to_float(tf.size(y))\n",
    "    return tloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to generate the transformed image\n",
    "with tf.Graph().as_default(),tf.Session() as sess:\n",
    "    \n",
    "    new_img = imageio.imread(\"../data/content/image_to_convert.jpg\")\n",
    "\n",
    "    content_input = tf.placeholder(tf.float32,shape=(1,new_img.shape[0],new_img.shape[1],3),name='content_ip')\n",
    "    ####################################################################################################################\n",
    "    generated_image = fast_model(content_input/255.0)\n",
    "    ####################################################################################################################\n",
    "    sess.run(tf.global_variables_initializer())  \n",
    "    ###################################################################################################################\n",
    "    restore_model = True\n",
    "    generate_image = True\n",
    "    \n",
    "    #load the trained model weights into the network\n",
    "    if(restore_model):\n",
    "        saver =  tf.train.Saver()  \n",
    "        saver.restore(sess,'../models/style/20180817-1/style_model_2')\n",
    "    ###################################################################################################################\n",
    "\n",
    "    if(generate_image):\n",
    "        imshow(new_img)\n",
    "        new_img = new_img.reshape(1,new_img.shape[0],new_img.shape[1],new_img.shape[2])\n",
    "        \n",
    "        gen_img = sess.run(generated_image,{content_input:new_img})\n",
    "        gen_img = gen_img.reshape(gen_img.shape[1],gen_img.shape[2],gen_img.shape[3])\n",
    "        gen_img = np.clip(gen_img, 0, 255).astype('uint8')\n",
    "        imshow(gen_img)\n",
    "        imageio.imwrite(\"../data/generated/converted_image.jpg\", gen_img) \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
